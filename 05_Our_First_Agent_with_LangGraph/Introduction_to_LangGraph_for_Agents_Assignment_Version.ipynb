{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJXW_DgiSebM"
   },
   "source": [
    "# LangGraph and LangSmith - Agentic RAG Powered by LangChain\n",
    "\n",
    "In the following notebook we'll complete the following tasks:\n",
    "\n",
    "- ğŸ¤ Breakout Room #1:\n",
    "  1. Install required libraries\n",
    "  2. Set Environment Variables\n",
    "  3. Creating our Tool Belt\n",
    "  4. Creating Our State\n",
    "  5. Creating and Compiling A Graph!\n",
    "\n",
    "- ğŸ¤ Breakout Room #2:\n",
    "  1. Evaluating the LangGraph Application with LangSmith\n",
    "  2. Adding Helpfulness Check and \"Loop\" Limits\n",
    "  3. LangGraph for the \"Patterns\" of GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djQ3nRAgoF67"
   },
   "source": [
    "# ğŸ¤ Breakout Room #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7pQDUhUnIo8"
   },
   "source": [
    "## Part 1: LangGraph - Building Cyclic Applications with LangChain\n",
    "\n",
    "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
    "\n",
    "### Why Cycles?\n",
    "\n",
    "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
    "\n",
    "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
    "\n",
    "### Why LangGraph?\n",
    "\n",
    "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_fLDElOVoop"
   },
   "source": [
    "## Task 1:  Dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wujPjGJuoPwg"
   },
   "source": [
    "## Task 2: Environment Variables\n",
    "\n",
    "We'll want to set our OpenAI, Tavily, and LangSmith API keys along with our LangSmith environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jdh8CoVWHRvs",
    "outputId": "3fa78560-393c-4ee5-b871-9886bf0d70f4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jkla2fpx28QK",
    "outputId": "52d7ad22-fcb1-4abe-853b-216c55a12650"
   },
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nv0glIDyHmRt",
    "outputId": "b69df90a-b4e1-4ddb-9de0-882d98b68ab2"
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE8 - LangGraph - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBRyQmEAVzua"
   },
   "source": [
    "## Task 3: Creating our Tool Belt\n",
    "\n",
    "As is usually the case, we'll want to equip our agent with a toolbelt to help answer questions and add external knowledge.\n",
    "\n",
    "There's a tonne of tools in the [LangChain Community Repo](https://github.com/langchain-ai/langchain-community/tree/main/libs/community) but we'll stick to a couple just so we can observe the cyclic nature of LangGraph in action!\n",
    "\n",
    "We'll leverage:\n",
    "\n",
    "- [Tavily Search Results](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/tavily_search/tool.py)\n",
    "- [Arxiv](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/arxiv/tool.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2k6n_Dob2F46"
   },
   "source": [
    "#### ğŸ—ï¸ Activity #1:\n",
    "\n",
    "Please add the tools to use into our toolbelt.\n",
    "\n",
    "> NOTE: Each tool in our toolbelt should be a method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "lAxaSvlfIeOg"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "tool_belt = [\n",
    "    tavily_tool,\n",
    "    ArxivQueryRun(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VI-C669ZYVI5"
   },
   "source": [
    "### Model\n",
    "\n",
    "Now we can set-up our model! We'll leverage the familiar OpenAI model suite for this example - but it's not *necessary* to use with LangGraph. LangGraph supports all models - though you might not find success with smaller models - as such, they recommend you stick with:\n",
    "\n",
    "- OpenAI's GPT-3.5 and GPT-4\n",
    "- Anthropic's Claude\n",
    "- Google's Gemini\n",
    "\n",
    "> NOTE: Because we're leveraging the OpenAI function calling API - we'll need to use OpenAI *for this specific example* (or any other service that exposes an OpenAI-style function calling API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "QkNS8rNZJs4z"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ugkj3GzuZpQv"
   },
   "source": [
    "Now that we have our model set-up, let's \"put on the tool belt\", which is to say: We'll bind our LangChain formatted tools to the model in an OpenAI function calling format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "4OdMqFafZ_0V"
   },
   "outputs": [],
   "source": [
    "model = model.bind_tools(tool_belt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERzuGo6W18Lr"
   },
   "source": [
    "#### â“ Question #1:\n",
    "\n",
    "How does the model determine which tool to use?\n",
    "\n",
    "The model uses a bunch of different methods to determine which tool to use. \n",
    "It can start with context analysis, which is just analyzing the user's request to understand the type of task being asked. This can mean looking for key words or phrases that determine which tool or approach to go with.\n",
    "The model then probably has some logic in place to figure out which tool to use. It uses pattern recognition as a sort of mapping from request to tool. For example, a request for current info would mean a web search with tavily, vs using arxiv or some sort of archive for any academic papers or scientific accuracy is necessary.\n",
    "The model would then use a decision framework and go down the list of questions before picking the right tool.\n",
    "The model would also continue training and get better at choosing the right tool for specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_296Ub96Z_H8"
   },
   "source": [
    "## Task 4: Putting the State in Stateful\n",
    "\n",
    "Earlier we used this phrasing:\n",
    "\n",
    "`coordinated multi-actor and stateful applications`\n",
    "\n",
    "So what does that \"stateful\" mean?\n",
    "\n",
    "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
    "\n",
    "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
    "\n",
    "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
    "\n",
    "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
    "\n",
    "1. We initialize our state object:\n",
    "  - `{\"messages\" : []}`\n",
    "2. Our user submits a query to our application.\n",
    "  - New State: `HumanMessage(#1)`\n",
    "  - `{\"messages\" : [HumanMessage(#1)}`\n",
    "3. We pass our state object to an Agent node which is able to read the current state. It will use the last `HumanMessage` as input. It gets some kind of output which it will add to the state.\n",
    "  - New State: `AgentMessage(#1, additional_kwargs {\"function_call\" : \"WebSearchTool\"})`\n",
    "  - `{\"messages\" : [HumanMessage(#1), AgentMessage(#1, ...)]}`\n",
    "4. We pass our state object to a \"conditional node\" (more on this later) which reads the last state to determine if we need to use a tool - which it can determine properly because of our provided object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "mxL9b_NZKUdL"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWsMhfO9grLu"
   },
   "source": [
    "## Task 5: It's Graphing Time!\n",
    "\n",
    "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
    "\n",
    "Let's take a second to refresh ourselves about what a graph is in this context.\n",
    "\n",
    "Graphs, also called networks in some circles, are a collection of connected objects.\n",
    "\n",
    "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
    "\n",
    "Let's look at a simple graph.\n",
    "\n",
    "![image](https://i.imgur.com/2NFLnIc.png)\n",
    "\n",
    "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
    "\n",
    "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL runnable.\n",
    "\n",
    "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".\n",
    "\n",
    "Let's create some nodes and expand on our diagram.\n",
    "\n",
    "> NOTE: Due to the tight integration with LCEL - we can comfortably create our nodes in an async fashion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "91flJWtZLUrl"
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "def call_model(state):\n",
    "  messages = state[\"messages\"]\n",
    "  response = model.invoke(messages)\n",
    "  return {\"messages\" : [response]}\n",
    "\n",
    "tool_node = ToolNode(tool_belt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bwR7MgWj3Wg"
   },
   "source": [
    "Now we have two total nodes. We have:\n",
    "\n",
    "- `call_model` is a node that will...well...call the model\n",
    "- `tool_node` is a node which can call a tool\n",
    "\n",
    "Let's start adding nodes! We'll update our diagram along the way to keep track of what this looks like!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vF4_lgtmQNo",
    "outputId": "a4384377-8f7a-415f-be1b-fee6169cb101"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x118282650>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "uncompiled_graph = StateGraph(AgentState)\n",
    "\n",
    "uncompiled_graph.add_node(\"agent\", call_model)\n",
    "uncompiled_graph.add_node(\"action\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8CjRlbVmRpW"
   },
   "source": [
    "Let's look at what we have so far:\n",
    "\n",
    "![image](https://i.imgur.com/md7inqG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaXHpPeSnOWC"
   },
   "source": [
    "Next, we'll add our entrypoint. All our entrypoint does is indicate which node is called first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGCbaYqRnmiw",
    "outputId": "5351807c-2ac7-4316-a3a3-878abeacd114"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x118282650>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncompiled_graph.set_entry_point(\"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUsfGoSpoF9U"
   },
   "source": [
    "![image](https://i.imgur.com/wNixpJe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Q_pQgHmoW0M"
   },
   "source": [
    "Now we want to build a \"conditional edge\" which will use the output state of a node to determine which path to follow.\n",
    "\n",
    "We can help conceptualize this by thinking of our conditional edge as a conditional in a flowchart!\n",
    "\n",
    "Notice how our function simply checks if there is a \"function_call\" kwarg present.\n",
    "\n",
    "Then we create an edge where the origin node is our agent node and our destination node is *either* the action node or the END (finish the graph).\n",
    "\n",
    "It's important to highlight that the dictionary passed in as the third parameter (the mapping) should be created with the possible outputs of our conditional function in mind. In this case `should_continue` outputs either `\"end\"` or `\"continue\"` which are subsequently mapped to the action node or the END node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BZgb81VQf9o",
    "outputId": "73a07c15-5f0b-40f2-b033-38b57d056dd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x118282650>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def should_continue(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  if last_message.tool_calls:\n",
    "    return \"action\"\n",
    "\n",
    "  return END\n",
    "\n",
    "uncompiled_graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Cvhcf4jp0Ce"
   },
   "source": [
    "Let's visualize what this looks like.\n",
    "\n",
    "![image](https://i.imgur.com/8ZNwKI5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKCjWJCkrJb9"
   },
   "source": [
    "Finally, we can add our last edge which will connect our action node to our agent node. This is because we *always* want our action node (which is used to call our tools) to return its output to our agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvcgbHf1rIXZ",
    "outputId": "45d4bdd6-d6bb-4a1d-bb79-cad43c130bf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x118282650>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncompiled_graph.add_edge(\"action\", \"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiWDwBQtrw7Z"
   },
   "source": [
    "Let's look at the final visualization.\n",
    "\n",
    "![image](https://i.imgur.com/NWO7usO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYqDpErlsCsu"
   },
   "source": [
    "All that's left to do now is to compile our workflow - and we're off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "zt9-KS8DpzNx"
   },
   "outputs": [],
   "source": [
    "simple_agent_graph = uncompiled_graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhNWIwBL1W4Q"
   },
   "source": [
    "#### â“ Question #2:\n",
    "\n",
    "Is there any specific limit to how many times we can cycle?\n",
    "There is no explicit limit to how many times we can cycle. The graph will keep looping until it reaches a terminal node, there is an end that is reached, an exception is thrown, or some other constraint is hit. This could cause infinite loops and also create a bad user experience.\n",
    "\n",
    "If not, how could we impose a limit to the number of cycles?\n",
    "Because there are no inherit limits, we can impose them a couple different ways. We could add a counter and have a max number of retries or cycles. You could also impost a time limit and end the cycle if it hits that limit. Another way to end the cycle is end it once the result hits a certain threshold of quality or accuracy, but that would mean another check to verify quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEYcTShCsPaa"
   },
   "source": [
    "## Using Our Graph\n",
    "\n",
    "Now that we've created and compiled our graph - we can call it *just as we'd call any other* `Runnable`!\n",
    "\n",
    "Let's try out a few examples to see how it fairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qn4n37PQRPII",
    "outputId": "5eeedfae-089d-496e-e71f-071939fa5832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='Technical professionals are using AI in various ways to enhance their work, including automating repetitive tasks, improving decision-making, analyzing large datasets, developing new products and services, and optimizing processes. They leverage AI for tasks such as machine learning model development, natural language processing, computer vision, predictive analytics, and automation. This integration helps increase efficiency, accuracy, and innovation across different industries. Would you like specific examples from particular fields or industries?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 163, 'total_tokens': 251, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLKIR4AOHIGEvIbCQV4YZV9hZ6qkG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c4842668-a50c-40bd-899d-b6fc7f07d606-0', usage_metadata={'input_tokens': 163, 'output_tokens': 88, 'total_tokens': 251, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\" : [HumanMessage(content=\"How are technical professionals using AI to improve their work?\")]}\n",
    "\n",
    "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        print(values[\"messages\"])\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBHnUtLSscRr"
   },
   "source": [
    "Let's look at what happened:\n",
    "\n",
    "1. Our state object was populated with our request\n",
    "2. The state object was passed into our entry point (agent node) and the agent node added an `AIMessage` to the state object and passed it along the conditional edge\n",
    "3. The conditional edge received the state object, found the \"tool_calls\" `additional_kwarg`, and sent the state object to the action node\n",
    "4. The action node added the response from the OpenAI function calling endpoint to the state object and passed it along the edge to the agent node\n",
    "5. The agent node added a response to the state object and passed it along the conditional edge\n",
    "6. The conditional edge received the state object, could not find the \"tool_calls\" `additional_kwarg` and passed the state object to END where we see it output in the cell above!\n",
    "\n",
    "Now let's look at an example that shows a multiple tool usage - all with the same flow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afv2BuEsV5JG",
    "outputId": "ff009536-d281-4a56-c126-9cd245352bfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sTlklWpnHlwkeIxsZGqA9r6N', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_UvLrIsSVn1AVR4mWJeJQyDeI', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research paper\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 182, 'total_tokens': 241, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLKITHnCdGhDWKoAC1BpL9TSmjqiB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--42a5600c-b869-455b-8f25-010104d82350-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'A Comprehensive Survey of Deep Research'}, 'id': 'call_sTlklWpnHlwkeIxsZGqA9r6N', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'A Comprehensive Survey of Deep Research paper'}, 'id': 'call_UvLrIsSVn1AVR4mWJeJQyDeI', 'type': 'tool_call'}], usage_metadata={'input_tokens': 182, 'output_tokens': 59, 'total_tokens': 241, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'action'\n",
      "Tool Used: arxiv\n",
      "[ToolMessage(content='Published: 2025-06-14\\nTitle: A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\nAuthors: Renjun Xu, Jingwen Peng\\nSummary: This survey examines the rapidly evolving field of Deep Research systems --\\nAI-powered applications that automate complex research workflows through the\\nintegration of large language models, advanced information retrieval, and\\nautonomous reasoning capabilities. We analyze more than 80 commercial and\\nnon-commercial implementations that have emerged since 2023, including\\nOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and\\nnumerous open-source alternatives. Through comprehensive examination, we\\npropose a novel hierarchical taxonomy that categorizes systems according to\\nfour fundamental technical dimensions: foundation models and reasoning engines,\\ntool utilization and environmental interaction, task planning and execution\\ncontrol, and knowledge synthesis and output generation. We explore the\\narchitectural patterns, implementation approaches, and domain-specific\\nadaptations that characterize these systems across academic, scientific,\\nbusiness, and educational applications. Our analysis reveals both the\\nsignificant capabilities of current implementations and the technical and\\nethical challenges they present regarding information accuracy, privacy,\\nintellectual property, and accessibility. The survey concludes by identifying\\npromising research directions in advanced reasoning architectures, multimodal\\nintegration, domain specialization, human-AI collaboration, and ecosystem\\nstandardization that will likely shape the future evolution of this\\ntransformative technology. By providing a comprehensive framework for\\nunderstanding Deep Research systems, this survey contributes to both the\\ntheoretical understanding of AI-augmented knowledge work and the practical\\ndevelopment of more capable, responsible, and accessible research technologies.\\nThe paper resources can be viewed at\\nhttps://github.com/scienceaix/deepresearch.\\n\\nPublished: 2021-03-05\\nTitle: A comprehensive survey on point cloud registration\\nAuthors: Xiaoshui Huang, Guofeng Mei, Jian Zhang, Rana Abbas\\nSummary: Registration is a transformation estimation problem between two point clouds,\\nwhich has a unique and critical role in numerous computer vision applications.\\nThe developments of optimization-based methods and deep learning methods have\\nimproved registration robustness and efficiency. Recently, the combinations of\\noptimization-based and deep learning methods have further improved performance.\\nHowever, the connections between optimization-based and deep learning methods\\nare still unclear. Moreover, with the recent development of 3D sensors and 3D\\nreconstruction techniques, a new research direction emerges to align\\ncross-source point clouds. This survey conducts a comprehensive survey,\\nincluding both same-source and cross-source registration methods, and summarize\\nthe connections between optimization-based and deep learning methods, to\\nprovide further research insight. This survey also builds a new benchmark to\\nevaluate the state-of-the-art registration algorithms in solving cross-source\\nchallenges. Besides, this survey summarizes the benchmark data sets and\\ndiscusses point cloud registration applications across various domains.\\nFinally, this survey proposes potential research directions in this rapidly\\ngrowing field.\\n\\nPublished: 2023-07-07\\nTitle: A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision\\nAuthors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang\\nSummary: Deep learning has the potential to revolutionize sports performance, with\\napplications ranging from perception and comprehension to decision. This paper\\npresents a comprehensive survey of deep learning in sports performance,\\nfocusing on three main aspects: algorithms, datasets and virtual environments,\\nand challenges. Firstly, we discuss th', name='arxiv', id='32e70561-93b9-4373-9e95-8a83dd494692', tool_call_id='call_sTlklWpnHlwkeIxsZGqA9r6N'), ToolMessage(content='[{\"title\": \"A Comprehensive Survey of Deep Research\", \"url\": \"https://arxiv.org/pdf/2506.12594?\", \"content\": \"by R XuÂ·2025Â·Cited by 11â€”Thissurveyexamines the rapidly evolving field ofDeep Researchsystemsâ€”AI-powered applications that automate complexresearchworkflows\", \"score\": 0.98597}, {\"title\": \"[2506.12594] A Comprehensive Survey of Deep Research\", \"url\": \"https://arxiv.org/abs/2506.12594\", \"content\": \"View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors > Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. By providing a comprehensive framework for understanding Deep Research systems, this survey contributes to both the theoretical understanding of AI-augmented knowledge work and the practical development of more capable, responsible, and accessible research technologies. | Cite as: | arXiv:2506.12594 [cs.AI] | View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors\", \"score\": 0.98519}, {\"title\": \"LLM Research Papers: The 2025 List (January to June)\", \"url\": \"https://magazine.sebastianraschka.com/p/llm-research-papers-2025-list-one\", \"content\": \"*   12 Mar, Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning, [https://arxiv.org/abs/2503.09516](https://arxiv.org/abs/2503.09516) *   20 Mar, Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn\\'t, [https://arxiv.org/abs/2503.16219](https://arxiv.org/abs/2503.16219) *   25 Mar, ReSearch: Learning to Reason with Search for LLMs via Reinforcement Learning, [https://arxiv.org/abs/2503.19470](https://arxiv.org/abs/2503.19470) *   31 Mar, Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model, [https://arxiv.org/abs/2503.24290](https://arxiv.org/abs/2503.24290) *   29 Apr, Reinforcement Learning for Reasoning in Large Language Models with One Training Example, [https://arxiv.org/abs/2504.20571](https://arxiv.org/abs/2504.20571) *   12 May, INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized Reinforcement Learning, [https://arxiv.org/abs/2505.07291](https://arxiv.org/abs/2505.07291) *   19 May, AdaptThink: Reasoning Models Can Learn When to Think, [https://arxiv.org/abs/2505.13417](https://arxiv.org/abs/2505.13417) *   30 May, ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models, [https://arxiv.org/abs/2505.24864](https://arxiv.org/abs/2505.24864)\", \"score\": 0.98386}, {\"title\": \"A Comprehensive Survey of Deep Research: Systems ...\", \"url\": \"https://arxiv.org/html/2506.12594v1\", \"content\": \"Jun 14, 2025â€”This survey examines the rapidly evolving field ofDeepResearch systemsâ€”AI-powered applications that automate complex research workflows\", \"score\": 0.98019}, {\"title\": \"Introducing deep research\", \"url\": \"https://openai.com/index/introducing-deep-research/\", \"content\": \"An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.\", \"score\": 0.97543}]', name='tavily_search_results_json', id='18a9b0a3-d309-4f65-82c2-a1e782d1e6bb', tool_call_id='call_UvLrIsSVn1AVR4mWJeJQyDeI', artifact={'query': 'A Comprehensive Survey of Deep Research paper', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://arxiv.org/pdf/2506.12594?', 'title': 'A Comprehensive Survey of Deep Research', 'content': 'by R XuÂ·2025Â·Cited by 11â€”Thissurveyexamines the rapidly evolving field ofDeep Researchsystemsâ€”AI-powered applications that automate complexresearchworkflows', 'score': 0.98597, 'raw_content': None}, {'url': 'https://arxiv.org/abs/2506.12594', 'title': '[2506.12594] A Comprehensive Survey of Deep Research', 'content': 'View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors > Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. By providing a comprehensive framework for understanding Deep Research systems, this survey contributes to both the theoretical understanding of AI-augmented knowledge work and the practical development of more capable, responsible, and accessible research technologies. | Cite as: | arXiv:2506.12594 [cs.AI] | View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors', 'score': 0.98519, 'raw_content': None}, {'url': 'https://magazine.sebastianraschka.com/p/llm-research-papers-2025-list-one', 'title': 'LLM Research Papers: The 2025 List (January to June)', 'content': \"*   12 Mar, Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning, [https://arxiv.org/abs/2503.09516](https://arxiv.org/abs/2503.09516) *   20 Mar, Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn't, [https://arxiv.org/abs/2503.16219](https://arxiv.org/abs/2503.16219) *   25 Mar, ReSearch: Learning to Reason with Search for LLMs via Reinforcement Learning, [https://arxiv.org/abs/2503.19470](https://arxiv.org/abs/2503.19470) *   31 Mar, Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model, [https://arxiv.org/abs/2503.24290](https://arxiv.org/abs/2503.24290) *   29 Apr, Reinforcement Learning for Reasoning in Large Language Models with One Training Example, [https://arxiv.org/abs/2504.20571](https://arxiv.org/abs/2504.20571) *   12 May, INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized Reinforcement Learning, [https://arxiv.org/abs/2505.07291](https://arxiv.org/abs/2505.07291) *   19 May, AdaptThink: Reasoning Models Can Learn When to Think, [https://arxiv.org/abs/2505.13417](https://arxiv.org/abs/2505.13417) *   30 May, ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models, [https://arxiv.org/abs/2505.24864](https://arxiv.org/abs/2505.24864)\", 'score': 0.98386, 'raw_content': None}, {'url': 'https://arxiv.org/html/2506.12594v1', 'title': 'A Comprehensive Survey of Deep Research: Systems ...', 'content': 'Jun 14, 2025â€”This survey examines the rapidly evolving field ofDeepResearch systemsâ€”AI-powered applications that automate complex research workflows', 'score': 0.98019, 'raw_content': None}, {'url': 'https://openai.com/index/introducing-deep-research/', 'title': 'Introducing deep research', 'content': 'An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.', 'score': 0.97543, 'raw_content': None}], 'response_time': 2.75, 'request_id': '40a7ce4f-9217-438c-b246-5858fd880f2d'})]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='I found the research paper titled \"A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\" authored by Renjun Xu and Jingwen Peng, published in 2025. \\n\\nNow, I will search for the current affiliations of the authors.', additional_kwargs={'tool_calls': [{'id': 'call_OqQvQrdQTLaMpFg8nWmPWkej', 'function': {'arguments': '{\"query\": \"Renjun Xu\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_jRIKFrzfwEqbMNnDRtdfCD8m', 'function': {'arguments': '{\"query\": \"Jingwen Peng\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 1950, 'total_tokens': 2060, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLKIZmcqtQOOKpo4CknFC7KW5pexT', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ad255f10-6827-4a8c-9e9b-92e893881417-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Renjun Xu'}, 'id': 'call_OqQvQrdQTLaMpFg8nWmPWkej', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Jingwen Peng'}, 'id': 'call_jRIKFrzfwEqbMNnDRtdfCD8m', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1950, 'output_tokens': 110, 'total_tokens': 2060, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'action'\n",
      "Tool Used: tavily_search_results_json\n",
      "[ToolMessage(content='[{\"title\": \"Renjun Xu - Researcher, Zhejiang University\", \"url\": \"https://openreview.net/profile?id=~Renjun_Xu1\", \"content\": \"# Renjun Xu\\\\n\\\\n### Principal Researcher, Zhejiang University\\\\n\\\\n Joined September 2021\\\\n\\\\n#### Names\\\\n\\\\nRenjun Xu (Preferred)\\\\n\\\\n Suggest Name\\\\n\\\\n#### Emails\\\\n\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\@zju.edu.cn (Confirmed)\\\\n\\\\n Suggest Email\\\\n\\\\n#### Personal Links\\\\n\\\\nHomepage\\\\n\\\\nDBLP\\\\n\\\\nORCID\\\\n\\\\nSemantic Scholar\\\\n\\\\n Suggest URL\\\\n\\\\n#### Career & Education History\\\\n\\\\nPrincipal Researcher\\\\n\\\\nZhejiang University(zju.edu.cn)\\\\n\\\\n2018 â€“ Present\\\\n\\\\n Suggest Position\\\\n\\\\n#### Advisors, Relations & Conflicts\\\\n\\\\nNo relations added\\\\n\\\\n Suggest Relation\\\\n\\\\n#### Expertise [...] equivariant neural network, domain adaptation, domain generalization, molecular, physics, contrastive learning, symmetry, crystal, phase transition\\\\n\\\\nPresent\\\\n\\\\n Suggest Expertise\", \"score\": 0.7171114}, {\"title\": \"Renyuan Xu Honored with Prestigious NSF CAREER Award\", \"url\": \"https://viterbischool.usc.edu/news/2024/06/renyuan-xu-honored-with-prestigious-nsf-career-award/\", \"content\": \"Xu is an emerging research leader who harnesses machine learning and probability tools to improve decision-making in fields that experience a high degree of uncertainty, such as the financial and economic systems, or in public policy, such as the design of fair contracts and the allocation of social resources. [...] WiSE Gabilan Assistant Professor of Industrial and Systems Engineering Renyuan Xu has been recognized with the prestigious National Science Foundation (NSF) CAREER Award for 2024.\\u202fThe award honors early-career faculty members with the potential to serve as academic role models in research and education to lead advances in their respective fields. The NSF selects CAREER Award recipients who are building a firm foundation for a lifetime of leadership in integrating education and research. [...] Xu joined the Daniel J. Epstein Department of Industrial and Systems Engineering in 2021 following a two-year role as a Hooke Research Fellow at Oxford Universityâ€™s Mathematical Institute.\\\\n\\\\nShe completed her undergraduate studies in mathematics at the University of Science and Technology of China before moving to the U.S. for her Ph.D. at UC Berkeley in the Department of Industrial Engineering and Operations Research.\", \"score\": 0.6501347}, {\"title\": \"Renjun Xu - Center for Data Science, Zhejiang University\", \"url\": \"https://www.aminer.cn/profile/renjun-xu/53f42ceddabfaedd74d30355?source=bz1\", \"content\": \"Renjun Xu - Center for Data Science, Zhejiang University | äººæ‰ç”»åƒ - AMiner\\\\n\\\\n\\\\n\\\\nResearch\\\\n\\\\nCenter for Data Science Zhejiang University\\\\n\\\\nã€ã€ŠInternational Joint Conference on Artificial Intelligenceã€‹(IJCAI, CCF-A), ã€ŠIEEE Transactions on Knowledge and Data Engineeringã€‹(TKDE, CCF-A)äº¤å‰é¢†åŸŸå‘è¡¨å¤šç¯‡å›½é™…é¡¶å°–æœŸåˆŠå’Œä¼šè®®æ–‡ç« ï¼ŒCVPRã€AAAIã€NIPSã€TPAMIã€TIPã€TLTç­‰é¡¶çº§äººå·¥æ™ºèƒ½æœŸåˆŠå’Œä¼šè®®ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ï¼Œè£è·2020å¹´åº¦ä¸–ç•Œäººå·¥æ™ºèƒ½å¤§ä¼šé’å¹´ä¼˜ç§€è®ºæ–‡æåå¥–ï¼ŒæŒ‡å¯¼å¹¶æ¨èçš„æ‰€æœ‰å­¦ç”Ÿå‡å·²æ‹¿åˆ°éº»çœç†å·¥å­¦é™¢(MIT)ã€å¡å†…åŸºæ¢…éš†å¤§å­¦(CMU)ç­‰å…¨çƒé¡¶å°–åæ ¡çš„offerï¼\\\\n\\\\nEducation\\\\n\\\\nSign in to view more\\\\n\\\\nExperience\\\\n\\\\nSign in to view more [...] The page data are from open Internet sources, cooperative publishers and automatic analysis results through AI technology. We do not make any commitments and guarantees for the validity, accuracy, correctness, reliability, completeness and timeliness of the page data. If you have any questions, please contact us by email: report@aminer.cn\\\\n\\\\nSwipe to Fine Result [...] Research Interests\\\\n\\\\n2012 2025\\\\n\\\\nPapers å…± 39 ç¯‡ Patents å…± 9 ç¯‡ Author Statistics Co-Author Similar Experts\\\\n\\\\nBy Year By Citation ä¸»é¢˜ç­›é€‰ æœŸåˆŠçº§åˆ«ç­›é€‰ åˆä½œè€…ç­›é€‰ åˆä½œæœºæ„ç­›é€‰\\\\n\\\\næ—¶é—´\\\\n\\\\nå¼•ç”¨é‡\\\\n\\\\nä¸»é¢˜\\\\n\\\\næœŸåˆŠçº§åˆ«\\\\n\\\\nåˆä½œè€…\\\\n\\\\nåˆä½œæœºæ„\\\\n\\\\nAll 2025 2024 2023 2022 2021 2020 2015 2014 2013 2012 2010 2006\\\\n\\\\nDo PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning Vs. Memorization in Large Language Models\\\\n\\\\nYang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan\\\\n\\\\narXiv Â· Computation and Languageï¼ˆ2025ï¼‰\\\\n\\\\nCited 0 Views 11 Bibtex\\\\n\\\\n0\\\\n\\\\n11\", \"score\": 0.6030211}, {\"title\": \"Renjun Hu\\'s Homepage\", \"url\": \"https://hurenjun.github.io/\", \"content\": \"various business domains including feed recommendation, user growth, online marketing, and LLM-as-a-Judge. Since January 2025, he has joined the School of Data Science and Engineering, East China Normal University as a young researcher. His recent research interests include robust machine learning and the understanding, evaluation, and applications of large language models. [...] Renjun Hu received his Bachelor\\'s degree in 2014 and Ph.D. in 2020 from the School of Computer Science and Engineering at Beihang University. From September 2017 to April 2018, he was a joint Ph.D. student in the Data Mining Group at Rutgers University. He then worked as a research intern at the Business Intelligence Lab of Baidu Research from May 2018 to September 2019. During 2020 to 2024, he served as an algorithm engineer at Alibaba Cloud, contributing to AI-driven transformations across [...] Young Researcher, East China Normal University, January 2025 - present\\\\n Algorithm engineer, Alibaba Group, July 2020 - January 2025\\\\n Research intern, Baidu Business Intelligence Lab, May 2018 - September 2019\\\\n Visiting student, Rutgers University, September 2017 - April 2018\", \"score\": 0.5760895}, {\"title\": \"RENJUN/Facts - NCT Wiki - Fandom\", \"url\": \"https://smtown-nctzens.fandom.com/wiki/RENJUN/Facts\", \"content\": \"He has a birthmark on the back of his hand\\\\n He used to have a snaggletooth back in 2016\\\\n He had/has lingual braces\\\\n He is one of the shortest members of NCT\\\\n He has a small dimple\\\\n\\\\n## Nicknames[]\\\\n\\\\n Golden Hands\\\\n Injeolmi\\\\n Injun (In-Joon)\\\\n JunJun\\\\n King of Losing\\\\n Moomin Otaku\\\\n Paper Doll/Man\\\\n Pure Boy\\\\n Shoulder Gangster\\\\n The One Who Brightens The World\\\\n The Prince of China\\\\n\\\\n## Relationships[] [...] Passed an online audition to SM Entertainment and got called the day before the actual audition date and so he talked to his parents and took a 3-hour train ride the next morning for the auditions and passed. RENJUN was accepted because of his dancing skills but after training, he became one of the main vocalists of NCT.\\\\n\\\\n## Personality[]\\\\n\\\\n## Appearance[] [...] RENJUN was a trainee for 1 year.\\\\n  + He was accepted to SM Entertainment through the 2015 Shenyang SM Global Audition, China in July.\\\\n  + RENJUN joined in 2015 and debuted in 2016.\\\\n He was announced as a NCT member in August 2016.\\\\n When watching the reality show, K-pop Star, RENJUN was indecisive on which company to audition to between SM, YG, and JYP. However, once he saw EXO, he decided to audition for SM\\'s Global Audition when he was 15 years old.\\\\n\\\\n#### Casting story[]\", \"score\": 0.49260366}]', name='tavily_search_results_json', id='d8bf474d-22d2-46e8-8354-8860dcbd2039', tool_call_id='call_OqQvQrdQTLaMpFg8nWmPWkej', artifact={'query': 'Renjun Xu', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://openreview.net/profile?id=~Renjun_Xu1', 'title': 'Renjun Xu - Researcher, Zhejiang University', 'content': '# Renjun Xu\\n\\n### Principal Researcher, Zhejiang University\\n\\n Joined September 2021\\n\\n#### Names\\n\\nRenjun Xu (Preferred)\\n\\n Suggest Name\\n\\n#### Emails\\n\\n\\\\\\\\\\\\\\\\@zju.edu.cn (Confirmed)\\n\\n Suggest Email\\n\\n#### Personal Links\\n\\nHomepage\\n\\nDBLP\\n\\nORCID\\n\\nSemantic Scholar\\n\\n Suggest URL\\n\\n#### Career & Education History\\n\\nPrincipal Researcher\\n\\nZhejiang University(zju.edu.cn)\\n\\n2018 â€“ Present\\n\\n Suggest Position\\n\\n#### Advisors, Relations & Conflicts\\n\\nNo relations added\\n\\n Suggest Relation\\n\\n#### Expertise [...] equivariant neural network, domain adaptation, domain generalization, molecular, physics, contrastive learning, symmetry, crystal, phase transition\\n\\nPresent\\n\\n Suggest Expertise', 'score': 0.7171114, 'raw_content': None}, {'url': 'https://viterbischool.usc.edu/news/2024/06/renyuan-xu-honored-with-prestigious-nsf-career-award/', 'title': 'Renyuan Xu Honored with Prestigious NSF CAREER Award', 'content': 'Xu is an emerging research leader who harnesses machine learning and probability tools to improve decision-making in fields that experience a high degree of uncertainty, such as the financial and economic systems, or in public policy, such as the design of fair contracts and the allocation of social resources. [...] WiSE Gabilan Assistant Professor of Industrial and Systems Engineering Renyuan Xu has been recognized with the prestigious National Science Foundation (NSF) CAREER Award for 2024.\\u202fThe award honors early-career faculty members with the potential to serve as academic role models in research and education to lead advances in their respective fields. The NSF selects CAREER Award recipients who are building a firm foundation for a lifetime of leadership in integrating education and research. [...] Xu joined the Daniel J. Epstein Department of Industrial and Systems Engineering in 2021 following a two-year role as a Hooke Research Fellow at Oxford Universityâ€™s Mathematical Institute.\\n\\nShe completed her undergraduate studies in mathematics at the University of Science and Technology of China before moving to the U.S. for her Ph.D. at UC Berkeley in the Department of Industrial Engineering and Operations Research.', 'score': 0.6501347, 'raw_content': None}, {'url': 'https://www.aminer.cn/profile/renjun-xu/53f42ceddabfaedd74d30355?source=bz1', 'title': 'Renjun Xu - Center for Data Science, Zhejiang University', 'content': 'Renjun Xu - Center for Data Science, Zhejiang University | äººæ‰ç”»åƒ - AMiner\\n\\n\\n\\nResearch\\n\\nCenter for Data Science Zhejiang University\\n\\nã€ã€ŠInternational Joint Conference on Artificial Intelligenceã€‹(IJCAI, CCF-A), ã€ŠIEEE Transactions on Knowledge and Data Engineeringã€‹(TKDE, CCF-A)äº¤å‰é¢†åŸŸå‘è¡¨å¤šç¯‡å›½é™…é¡¶å°–æœŸåˆŠå’Œä¼šè®®æ–‡ç« ï¼ŒCVPRã€AAAIã€NIPSã€TPAMIã€TIPã€TLTç­‰é¡¶çº§äººå·¥æ™ºèƒ½æœŸåˆŠå’Œä¼šè®®ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ï¼Œè£è·2020å¹´åº¦ä¸–ç•Œäººå·¥æ™ºèƒ½å¤§ä¼šé’å¹´ä¼˜ç§€è®ºæ–‡æåå¥–ï¼ŒæŒ‡å¯¼å¹¶æ¨èçš„æ‰€æœ‰å­¦ç”Ÿå‡å·²æ‹¿åˆ°éº»çœç†å·¥å­¦é™¢(MIT)ã€å¡å†…åŸºæ¢…éš†å¤§å­¦(CMU)ç­‰å…¨çƒé¡¶å°–åæ ¡çš„offerï¼\\n\\nEducation\\n\\nSign in to view more\\n\\nExperience\\n\\nSign in to view more [...] The page data are from open Internet sources, cooperative publishers and automatic analysis results through AI technology. We do not make any commitments and guarantees for the validity, accuracy, correctness, reliability, completeness and timeliness of the page data. If you have any questions, please contact us by email: report@aminer.cn\\n\\nSwipe to Fine Result [...] Research Interests\\n\\n2012 2025\\n\\nPapers å…± 39 ç¯‡ Patents å…± 9 ç¯‡ Author Statistics Co-Author Similar Experts\\n\\nBy Year By Citation ä¸»é¢˜ç­›é€‰ æœŸåˆŠçº§åˆ«ç­›é€‰ åˆä½œè€…ç­›é€‰ åˆä½œæœºæ„ç­›é€‰\\n\\næ—¶é—´\\n\\nå¼•ç”¨é‡\\n\\nä¸»é¢˜\\n\\næœŸåˆŠçº§åˆ«\\n\\nåˆä½œè€…\\n\\nåˆä½œæœºæ„\\n\\nAll 2025 2024 2023 2022 2021 2020 2015 2014 2013 2012 2010 2006\\n\\nDo PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning Vs. Memorization in Large Language Models\\n\\nYang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan\\n\\narXiv Â· Computation and Languageï¼ˆ2025ï¼‰\\n\\nCited 0 Views 11 Bibtex\\n\\n0\\n\\n11', 'score': 0.6030211, 'raw_content': None}, {'url': 'https://hurenjun.github.io/', 'title': \"Renjun Hu's Homepage\", 'content': \"various business domains including feed recommendation, user growth, online marketing, and LLM-as-a-Judge. Since January 2025, he has joined the School of Data Science and Engineering, East China Normal University as a young researcher. His recent research interests include robust machine learning and the understanding, evaluation, and applications of large language models. [...] Renjun Hu received his Bachelor's degree in 2014 and Ph.D. in 2020 from the School of Computer Science and Engineering at Beihang University. From September 2017 to April 2018, he was a joint Ph.D. student in the Data Mining Group at Rutgers University. He then worked as a research intern at the Business Intelligence Lab of Baidu Research from May 2018 to September 2019. During 2020 to 2024, he served as an algorithm engineer at Alibaba Cloud, contributing to AI-driven transformations across [...] Young Researcher, East China Normal University, January 2025 - present\\n Algorithm engineer, Alibaba Group, July 2020 - January 2025\\n Research intern, Baidu Business Intelligence Lab, May 2018 - September 2019\\n Visiting student, Rutgers University, September 2017 - April 2018\", 'score': 0.5760895, 'raw_content': None}, {'url': 'https://smtown-nctzens.fandom.com/wiki/RENJUN/Facts', 'title': 'RENJUN/Facts - NCT Wiki - Fandom', 'content': \"He has a birthmark on the back of his hand\\n He used to have a snaggletooth back in 2016\\n He had/has lingual braces\\n He is one of the shortest members of NCT\\n He has a small dimple\\n\\n## Nicknames[]\\n\\n Golden Hands\\n Injeolmi\\n Injun (In-Joon)\\n JunJun\\n King of Losing\\n Moomin Otaku\\n Paper Doll/Man\\n Pure Boy\\n Shoulder Gangster\\n The One Who Brightens The World\\n The Prince of China\\n\\n## Relationships[] [...] Passed an online audition to SM Entertainment and got called the day before the actual audition date and so he talked to his parents and took a 3-hour train ride the next morning for the auditions and passed. RENJUN was accepted because of his dancing skills but after training, he became one of the main vocalists of NCT.\\n\\n## Personality[]\\n\\n## Appearance[] [...] RENJUN was a trainee for 1 year.\\n  + He was accepted to SM Entertainment through the 2015 Shenyang SM Global Audition, China in July.\\n  + RENJUN joined in 2015 and debuted in 2016.\\n He was announced as a NCT member in August 2016.\\n When watching the reality show, K-pop Star, RENJUN was indecisive on which company to audition to between SM, YG, and JYP. However, once he saw EXO, he decided to audition for SM's Global Audition when he was 15 years old.\\n\\n#### Casting story[]\", 'score': 0.49260366, 'raw_content': None}], 'response_time': 1.34, 'request_id': '1e17f75a-8b5f-42b0-a28a-f55d55de9462'}), ToolMessage(content='[{\"title\": \"Jingwen Peng Email & Phone Number | Manulife Lead Analyst ...\", \"url\": \"https://rocketreach.co/jingwen-peng-email_28909123\", \"content\": \"Jingwen Peng, based in Boston, Massachusetts, United States, is currently a Lead Analyst, Investment Analytics at Manulife Investment Management at Manulife. Jingwen Peng brings experience from previous roles at Manulife Asset Management, Congress Asset Management and Prelude Asset Management. Jingwen Peng holds a 2008 - 2009 Master of Arts in Mathematical Finance @ Boston University Questrom School of Business. With a robust skill set that includes Quantitative Finance, Asset Management, [...] - [x]  see more  \\\\n   2010 - 2012 Research Analyst @ Congress Asset Management\\\\n   2009 - 2010 Research Analyst @ Prelude Asset Management\\\\n   2007 - 2007 Intern Analyst @ Bank of China\\\\n\\\\n see less  \\\\n\\\\n### Jingwen Peng Education\\\\n\\\\n   Boston University Questrom School of Business \\\\nMaster of Arts ( Mathematical Finance)\\\\n\\\\n2008 - 2009\\\\n   Peking University \\\\nBachelor of Science ( Mathematics with a concerntration in Financial Mathematics)\\\\n\\\\n2004 - 2008\\\\n\\\\n### Jingwen Peng Skills [...] Image 7: Liberty Mutual Investments Employee Jingwen Peng\\'s profile photo ### Jingwen Peng #### Director II - Lead Data Steward at Liberty Mutual Investments Boston, MA, US   View \\\\n\\\\n2\\\\n       hotmail.com\\\\n       libertymutualgroup.com\\\\n\\\\n   \\\\nImage 8: Bpifrance Assurance Export Employee Jingwen Peng\\'s profile photo ### Jingwen Peng #### Product owner at Bpifrance Assurance Export Pontoise, FR   View \\\\n\\\\n1\\\\n       bpifrance.fr\\\\n\\\\nView Similar Profiles\\\\n\\\\nTop Manulife Employees\", \"score\": 0.90869105}, {\"title\": \"Jingwen Peng - U of Rochester Simon STEM MSBA\", \"url\": \"https://www.linkedin.com/in/jpeng19\", \"content\": \"â—\\\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\\\n\\\\nâ—\\\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\\\n\\\\nâ—\\\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] - I\\'m excited to share that our consulting project with the Rochester Fire Department has been a resounding success! ğŸ‰ As part of a fantastic teamâ€¦  \\\\nLiked by Jingwen Peng  \\\\nView Post  \\\\nActivity Image\\\\n\\\\n- I\\'m thrilled to announce the completion of my first consulting project as Project Manager with Simon Vision Consulting! Working alongside myâ€¦  \\\\nLiked by Jingwen Peng  \\\\nView Post  \\\\nActivity Image\", \"score\": 0.6213807}, {\"title\": \"[PDF] Junwen Peng - The University of Oklahoma\", \"url\": \"https://www.ou.edu/content/dam/ogs/documents/information/CV_Peng%2C%20Junwen-24.01.pdf\", \"content\": \"1 Junwen Peng Business address: Sarkey Energy Center : 100 E. Boyd St., Suite T209 Norman, OK 73019 E-mail address: junwen.peng@ou.edu (junwen@utexas.edu; junwen.peng@cup.edu) Homepage:  Academic profile:  : WORK EXPERIENCE Oklahoma Geological Survey, The University of Oklahoma, Norman, U.S. 2023â€“Current \\uf09f Geologist â…¡ College of Geosciences, China University of Petroleum (CUP), Beijing, China 2021â€“2022 \\uf09f Lecturer (Top Young Talents) Bureau of Economic Geology, The University of Texas at Austin, [...] Austin, U.S. 2020â€“2021 \\uf09f Graduate research assistant ACADEMIC BACKGROUND Jackson School of Geosciences, The University of Texas at Austin, Austin, U.S. 2016â€“2021 \\uf09f Ph.D. in Geological Sciences College of Geosciences, China University of Petroleum (CUP), Beijing, China 2013â€“2016 \\uf09f M.Eng in Geological Resources and Geological Engineering Faculty of Earth Resources, China University of Geosciences (CUG), Wuhan, China 2009â€“2013 \\uf09f B.Eng in Resource Prospecting Engineering KEYWORDS OF EXPERTISE [...] of Geosciences (Top 1%) Jun.2013 National Scholarship of China (Top 1%), Ministry of Education of PR China Nov.2012 SINOPEC Excellent Student Scholarship (Top 1%), SINOPEC Nov.2011 Excellent Intern in Field Geological Skills Practice (Top 10%), China University of Geosciences Aug. 2011 REPRESENTATIVE CERTIFICATE & MEDIA ANNOUNCEMENT Li, Siguang Outstanding Student Award from Ministry of Science and Technology Division of China Outstanding Contribution in Reviewing of Marine and Petroleum\", \"score\": 0.57006866}, {\"title\": \"Loop | Jingwen Peng\", \"url\": \"https://loop.frontiersin.org/people/1381593/overview\", \"content\": \"0 Edited Research Topics\\\\n 0 Edited Publications\\\\n 0 Reviewed Publications\\\\n\\\\nView Editorial Contributions\\\\n\\\\n## Editorial Roles\\\\n\\\\nThis researcher does not have an active role on a Frontiers editorial board. You may recommend their participation\\\\nhere.\\\\n\\\\n 0\\\\n\\\\n  Followers\\\\n 0\\\\n\\\\n  Following\\\\n\\\\nNo content to display.\\\\n\\\\nView All Followers\\\\n\\\\nNo content to display.\\\\n\\\\nView All Following [...] Jingwen Peng\\\\n\\\\n Overview\\\\n Bio\\\\n Network0\\\\n Publications4\\\\n Editorial Contributions0\\\\n Impact\\\\n\\\\n 6,420Total\\\\n    \\\\n  Views\\\\n 14Profile  \\\\n  Views\\\\n 4Total  \\\\n  Publications\\\\n 6,406Publication  \\\\n  Views\\\\n 3,182Publications  \\\\n  Downloads\\\\n\\\\nView Full Impact\\\\n\\\\n## Brief Bio\\\\n\\\\nUsers who add a description significantly increase their chances for discovers and collaboration. Showcase your career and increase your impact by\\\\nadding your brief bio now.\\\\n\\\\nNo content to display.\\\\n\\\\nView Full Bio and Expertise\\\\n\\\\n## 4 Publications [...] Frontiers In and Loop are registered trade marks of Frontiers Media SA.  \\\\nÂ© Copyright 2007-2025 Frontiers Media SA. All rights reserved -\\\\nTerms and Conditions\", \"score\": 0.5325473}, {\"title\": \"April 2023 - K-State College of Veterinary Medicine\", \"url\": \"https://www.vet.k-state.edu/about/news-events-publications/lifelines/2023/2304.html\", \"content\": \"Hospitality Management. This year\\'s recipients from the veterinary college are: Grace Calo, Bailey Fritz, Angela Gaggiano, Valerie Haskett, Lilli Heinen, Nathan Jackson, Christina Marquez, Jingwen Peng, Katherine Stenger and Hanna Westermier.  David C. Poole, Departments of Anatomy and Physiology and Kinesiology, was invited to speak at the German National Academy of Sciences, in Leopoldina, Halle, Germany, this March. The apex physiology journal FUNCTION, editorâ€“in-chief, professor Ole\", \"score\": 0.48996773}]', name='tavily_search_results_json', id='3bd8b649-9ec8-4adf-ad60-4a5ffc1ff0b1', tool_call_id='call_jRIKFrzfwEqbMNnDRtdfCD8m', artifact={'query': 'Jingwen Peng', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://rocketreach.co/jingwen-peng-email_28909123', 'title': 'Jingwen Peng Email & Phone Number | Manulife Lead Analyst ...', 'content': \"Jingwen Peng, based in Boston, Massachusetts, United States, is currently a Lead Analyst, Investment Analytics at Manulife Investment Management at Manulife. Jingwen Peng brings experience from previous roles at Manulife Asset Management, Congress Asset Management and Prelude Asset Management. Jingwen Peng holds a 2008 - 2009 Master of Arts in Mathematical Finance @ Boston University Questrom School of Business. With a robust skill set that includes Quantitative Finance, Asset Management, [...] - [x]  see more  \\n   2010 - 2012 Research Analyst @ Congress Asset Management\\n   2009 - 2010 Research Analyst @ Prelude Asset Management\\n   2007 - 2007 Intern Analyst @ Bank of China\\n\\n see less  \\n\\n### Jingwen Peng Education\\n\\n   Boston University Questrom School of Business \\nMaster of Arts ( Mathematical Finance)\\n\\n2008 - 2009\\n   Peking University \\nBachelor of Science ( Mathematics with a concerntration in Financial Mathematics)\\n\\n2004 - 2008\\n\\n### Jingwen Peng Skills [...] Image 7: Liberty Mutual Investments Employee Jingwen Peng's profile photo ### Jingwen Peng #### Director II - Lead Data Steward at Liberty Mutual Investments Boston, MA, US   View \\n\\n2\\n       hotmail.com\\n       libertymutualgroup.com\\n\\n   \\nImage 8: Bpifrance Assurance Export Employee Jingwen Peng's profile photo ### Jingwen Peng #### Product owner at Bpifrance Assurance Export Pontoise, FR   View \\n\\n1\\n       bpifrance.fr\\n\\nView Similar Profiles\\n\\nTop Manulife Employees\", 'score': 0.90869105, 'raw_content': None}, {'url': 'https://www.linkedin.com/in/jpeng19', 'title': 'Jingwen Peng - U of Rochester Simon STEM MSBA', 'content': \"â—\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\n\\nâ—\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\n\\nâ—\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] - I'm excited to share that our consulting project with the Rochester Fire Department has been a resounding success! ğŸ‰ As part of a fantastic teamâ€¦  \\nLiked by Jingwen Peng  \\nView Post  \\nActivity Image\\n\\n- I'm thrilled to announce the completion of my first consulting project as Project Manager with Simon Vision Consulting! Working alongside myâ€¦  \\nLiked by Jingwen Peng  \\nView Post  \\nActivity Image\", 'score': 0.6213807, 'raw_content': None}, {'url': 'https://www.ou.edu/content/dam/ogs/documents/information/CV_Peng%2C%20Junwen-24.01.pdf', 'title': '[PDF] Junwen Peng - The University of Oklahoma', 'content': '1 Junwen Peng Business address: Sarkey Energy Center : 100 E. Boyd St., Suite T209 Norman, OK 73019 E-mail address: junwen.peng@ou.edu (junwen@utexas.edu; junwen.peng@cup.edu) Homepage:  Academic profile:  : WORK EXPERIENCE Oklahoma Geological Survey, The University of Oklahoma, Norman, U.S. 2023â€“Current \\uf09f Geologist â…¡ College of Geosciences, China University of Petroleum (CUP), Beijing, China 2021â€“2022 \\uf09f Lecturer (Top Young Talents) Bureau of Economic Geology, The University of Texas at Austin, [...] Austin, U.S. 2020â€“2021 \\uf09f Graduate research assistant ACADEMIC BACKGROUND Jackson School of Geosciences, The University of Texas at Austin, Austin, U.S. 2016â€“2021 \\uf09f Ph.D. in Geological Sciences College of Geosciences, China University of Petroleum (CUP), Beijing, China 2013â€“2016 \\uf09f M.Eng in Geological Resources and Geological Engineering Faculty of Earth Resources, China University of Geosciences (CUG), Wuhan, China 2009â€“2013 \\uf09f B.Eng in Resource Prospecting Engineering KEYWORDS OF EXPERTISE [...] of Geosciences (Top 1%) Jun.2013 National Scholarship of China (Top 1%), Ministry of Education of PR China Nov.2012 SINOPEC Excellent Student Scholarship (Top 1%), SINOPEC Nov.2011 Excellent Intern in Field Geological Skills Practice (Top 10%), China University of Geosciences Aug. 2011 REPRESENTATIVE CERTIFICATE & MEDIA ANNOUNCEMENT Li, Siguang Outstanding Student Award from Ministry of Science and Technology Division of China Outstanding Contribution in Reviewing of Marine and Petroleum', 'score': 0.57006866, 'raw_content': None}, {'url': 'https://loop.frontiersin.org/people/1381593/overview', 'title': 'Loop | Jingwen Peng', 'content': '0 Edited Research Topics\\n 0 Edited Publications\\n 0 Reviewed Publications\\n\\nView Editorial Contributions\\n\\n## Editorial Roles\\n\\nThis researcher does not have an active role on a Frontiers editorial board. You may recommend their participation\\nhere.\\n\\n 0\\n\\n  Followers\\n 0\\n\\n  Following\\n\\nNo content to display.\\n\\nView All Followers\\n\\nNo content to display.\\n\\nView All Following [...] Jingwen Peng\\n\\n Overview\\n Bio\\n Network0\\n Publications4\\n Editorial Contributions0\\n Impact\\n\\n 6,420Total\\n    \\n  Views\\n 14Profile  \\n  Views\\n 4Total  \\n  Publications\\n 6,406Publication  \\n  Views\\n 3,182Publications  \\n  Downloads\\n\\nView Full Impact\\n\\n## Brief Bio\\n\\nUsers who add a description significantly increase their chances for discovers and collaboration. Showcase your career and increase your impact by\\nadding your brief bio now.\\n\\nNo content to display.\\n\\nView Full Bio and Expertise\\n\\n## 4 Publications [...] Frontiers In and Loop are registered trade marks of Frontiers Media SA.  \\nÂ© Copyright 2007-2025 Frontiers Media SA. All rights reserved -\\nTerms and Conditions', 'score': 0.5325473, 'raw_content': None}, {'url': 'https://www.vet.k-state.edu/about/news-events-publications/lifelines/2023/2304.html', 'title': 'April 2023 - K-State College of Veterinary Medicine', 'content': \"Hospitality Management. This year's recipients from the veterinary college are: Grace Calo, Bailey Fritz, Angela Gaggiano, Valerie Haskett, Lilli Heinen, Nathan Jackson, Christina Marquez, Jingwen Peng, Katherine Stenger and Hanna Westermier.  David C. Poole, Departments of Anatomy and Physiology and Kinesiology, was invited to speak at the German National Academy of Sciences, in Leopoldina, Halle, Germany, this March. The apex physiology journal FUNCTION, editorâ€“in-chief, professor Ole\", 'score': 0.48996773, 'raw_content': None}], 'response_time': 0.98, 'request_id': 'f8e56f7b-ba88-417e-9e91-b714b0d93c8f'})]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='Renjun Xu is currently a Principal Researcher at Zhejiang University. Jingwen Peng is currently a Lead Analyst at Manulife Investment Management.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 5879, 'total_tokens': 5908, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLKIe2hlEnfgxETNwgV7bF6c154qf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2a2ba10f-1ce4-437b-9fcd-ced0da0b4e2b-0', usage_metadata={'input_tokens': 5879, 'output_tokens': 29, 'total_tokens': 5908, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\" : [HumanMessage(content=\"Search Arxiv for the A Comprehensive Survey of Deep Research paper, then search each of the authors to find out where they work now using Tavily!\")]}\n",
    "\n",
    "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        if node == \"action\":\n",
    "          print(f\"Tool Used: {values['messages'][0].name}\")\n",
    "        print(values[\"messages\"])\n",
    "\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXzDlZVz1Hnf"
   },
   "source": [
    "#### ğŸ—ï¸ Activity #2:\n",
    "\n",
    "Please write out the steps the agent took to arrive at the correct answer.\n",
    "\n",
    "1. Query processing.\n",
    "The agent got the query \"author of A Comprehensive Survey of Deep Research\" and decided to use 2 different tools, arxiv and tavily, to continue with the search. It decided to search for different things with each tool. For arxiv, it searched for the paper directly. It searched for the author(s) of the paper on Tavily.\n",
    "2. Tool execution - arxiv\n",
    "The agent did an arxiv search fo the paper, and the results returned multiple papers. The most relevant result was the first result of \"A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\" by Renjun Xu and Jingwen Peng\". \n",
    "3. Agent update - arxiv\n",
    "Once the agent was updated with the information above from the arxiv call, it made 2 more calls to Tavily to search for the individual authors. So one tavily call for Renjun and one for Jingwen\n",
    "4. Tool execution - tavily\n",
    "The agent simultaneously did a tavily search on who the authors of the paper were as step #2. It got results back about about both authors and their current occupations.\n",
    "5. Combination and result generation\n",
    "The agent combined results from both tools and the response was who the authors of the paper are and their current occupations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤ Breakout Room #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7c8-Uyarh1v"
   },
   "source": [
    "## Part 1: LangSmith Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pV3XeFOT1Sar"
   },
   "source": [
    "### Pre-processing for LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wruQCuzewUuO"
   },
   "source": [
    "To do a little bit more preprocessing, let's wrap our LangGraph agent in a simple chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "orYxBZXSxJjZ",
    "outputId": "76be837b-6424-4516-8f63-07fbd8c25bf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Deep Research is an advanced AI-powered research tool designed to conduct in-depth, multi-step investigations on the Internet. Unlike standard search or quick-response AI models, Deep Research autonomously finds, analyzes, and synthesizes information from numerous online sources to produce comprehensive and structured reports. It is capable of understanding complex queries, breaking them down into multiple research tasks, and consolidating the results into clear, detailed outputs. This technology is used to enhance the efficiency and depth of research in various fields, including academic, technical, and general information gathering.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_inputs(input_object):\n",
    "  return {\"messages\" : [HumanMessage(content=input_object[\"text\"])]}\n",
    "\n",
    "def parse_output(input_state):\n",
    "  return {\"answer\" : input_state[\"messages\"][-1].content}\n",
    "\n",
    "agent_chain_with_formatting = convert_inputs | simple_agent_graph | parse_output\n",
    "\n",
    "agent_chain_with_formatting.invoke({\"text\" : \"What is Deep Research?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9UkCIqkpyZu"
   },
   "source": [
    "### Task 1: Creating An Evaluation Dataset\n",
    "\n",
    "Just as we saw last week, we'll want to create a dataset to test our Agent's ability to answer questions.\n",
    "\n",
    "In order to do this - we'll want to provide some questions and some answers. Let's look at how we can create such a dataset below.\n",
    "\n",
    "```python\n",
    "questions = [\n",
    "    {\n",
    "        \"inputs\" : {\"text\" : \"Who were the main authors on the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' paper?\"},\n",
    "        \"outputs\" : {\"must_mention\" : [\"Peng\", \"Xu\"]}   \n",
    "    },\n",
    "    ...,\n",
    "    {\n",
    "        \"inputs\" : {\"text\" : \"Where do the authors of the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' work now?\"},\n",
    "        \"outputs\" : {\"must_mention\" : [\"Zhejiang\", \"Liberty Mutual\"]}\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfMXF2KAsQxs"
   },
   "source": [
    "#### ğŸ—ï¸ Activity #3:\n",
    "\n",
    "Please create a dataset in the above format with at least 5 questions that pertain to the cohort use-case (more information [here](https://www.notion.so/Session-4-RAG-with-LangGraph-OSS-Local-Models-Eval-w-LangSmith-26acd547af3d80838d5beba464d7e701#26acd547af3d81d08809c9c82a462bdd)), or the use-case you're hoping to tackle in your Demo Day project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "CbagRuJop83E"
   },
   "outputs": [],
   "source": [
    "# update these questions to your own\n",
    "questions = [\n",
    "    {\n",
    "        \"inputs\" : {\"text\" : \"How do people use AI in their daily work?\"},\n",
    "        \"outputs\" : {\"must_mention\" : [\"Efficiency\", \"Productivity\"]}   \n",
    "    },\n",
    "    {\n",
    "        \"inputs\" : {\"text\" : \"What are the most common ways people use AI in their work?\"},\n",
    "        \"outputs\" : {\"must_mention\" : [\"Tools\", \"Automations\", \"AI Agents\"]}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\" : {\"text\" : \"Do people use AI for their personal lives?\"},\n",
    "        \"outputs\" : {\"must_mention\" : [\"Personal\", \"Home\", \"Family\", \"Hobbies\"]}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\" : {\"text\" : \"What concerns or challenges do people have when using AI?\"},\n",
    "        \"outputs\" : {\"must_mention\" : [\"Privacy\", \"Security\", \"Ethics\", \"Bias\"]}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\" : {\"text\" : \"What should I build to add value to the local communities Iâ€™m engaged in?\"},\n",
    "        \"outputs\" : {\"must_mention\" : [\"Local\", \"Community\", \"Value\", \"Impact\"]}\n",
    "    },\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7QVFuAmsh7L"
   },
   "source": [
    "Now we can add our dataset to our LangSmith project using the following code which we saw last Thursday!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "RLfrZrgSsn85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['2abe6ea7-0438-4188-8eef-f63c4b06f1c6',\n",
       "  '47532cf6-9d8c-4caa-ab40-759c34fb8d9f',\n",
       "  '86bbcc28-3f1f-4fe0-b378-9d9ba13a5a60',\n",
       "  '0e80e056-7905-4407-9645-bb8eab86e931',\n",
       "  '8431ce2b-0cdb-4f65-901b-3dfea91c536c'],\n",
       " 'count': 5}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = f\"Simple Search Agent - Evaluation Dataset - {uuid4().hex[0:8]}\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Questions about the cohort use-case to evaluate the Simple Search Agent.\"\n",
    ")\n",
    "\n",
    "client.create_examples(\n",
    "    dataset_id=dataset.id,\n",
    "    examples=questions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lRTXUrTtP9Y"
   },
   "source": [
    "### Task 2: Adding Evaluators\n",
    "\n",
    "Let's use the OpenEvals library to product an evaluator that we can then pass into LangSmith!\n",
    "\n",
    "> NOTE: Examine the `CORRECTNESS_PROMPT` below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert data labeler evaluating model outputs for correctness. Your task is to assign a score based on the following rubric:\n",
      "\n",
      "<Rubric>\n",
      "  A correct answer:\n",
      "  - Provides accurate and complete information\n",
      "  - Contains no factual errors\n",
      "  - Addresses all parts of the question\n",
      "  - Is logically consistent\n",
      "  - Uses precise and accurate terminology\n",
      "\n",
      "  When scoring, you should penalize:\n",
      "  - Factual errors or inaccuracies\n",
      "  - Incomplete or partial answers\n",
      "  - Misleading or ambiguous statements\n",
      "  - Incorrect terminology\n",
      "  - Logical inconsistencies\n",
      "  - Missing key information\n",
      "</Rubric>\n",
      "\n",
      "<Instructions>\n",
      "  - Carefully read the input and output\n",
      "  - Check for factual accuracy and completeness\n",
      "  - Focus on correctness of information rather than style or verbosity\n",
      "</Instructions>\n",
      "\n",
      "<Reminder>\n",
      "  The goal is to evaluate factual correctness and completeness of the response.\n",
      "</Reminder>\n",
      "\n",
      "<input>\n",
      "{inputs}\n",
      "</input>\n",
      "\n",
      "<output>\n",
      "{outputs}\n",
      "</output>\n",
      "\n",
      "Use the reference outputs below to help you evaluate the correctness of the response:\n",
      "\n",
      "<reference_outputs>\n",
      "{reference_outputs}\n",
      "</reference_outputs>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openevals.prompts import CORRECTNESS_PROMPT\n",
    "print(CORRECTNESS_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "QrAUXMFftlAY"
   },
   "outputs": [],
   "source": [
    "from openevals.llm import create_llm_as_judge\n",
    "\n",
    "correctness_evaluator = create_llm_as_judge(\n",
    "        prompt=CORRECTNESS_PROMPT,\n",
    "        model=\"openai:o3-mini\", # very impactful to the final score\n",
    "        feedback_key=\"correctness\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create a custom Evaluator for our created dataset above - we do this by first making a simple Python function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def must_mention(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
    "  # determine if the phrases in the reference_outputs are in the outputs\n",
    "  required = reference_outputs.get(\"must_mention\") or []\n",
    "  score = all(phrase in outputs[\"answer\"] for phrase in required)\n",
    "  return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNtHORUh0jZY"
   },
   "source": [
    "#### â“ Question #4:\n",
    "\n",
    "What are some ways you could improve this metric as-is?\n",
    "\n",
    "> NOTE: Alternatively you can suggest where gaps exist in this method.\n",
    "\n",
    "Right now, we are checking for an exact match in the output that we have in our data set. Things like case sensitiviy would not be accounted for. For example, \"Efficiency\" is listed as a 'must-mention' output. However, if the output has a \"efficiency\", it would not match. The result also returns a boolean, so it is an all or nothing score. We should return a percentage instead, so a number between 0 and 1 of how close it matches our expected results. Lastly, there is no verification of whether the context of the result makes sense or whether the expected words are not the main focus of the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1RJr349zhv7"
   },
   "source": [
    "Task 3: Evaluating\n",
    "\n",
    "All that is left to do is evaluate our agent's response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "efcf57067cf743d8b4ce059a61cbe02e",
      "53e33aae3b97490c82aec7bbb0d6ebba",
      "ad84e0e971d3455db2efe7dd0d1f803e",
      "72adef9b70dd48198b7322b6c5b113cf",
      "8a61d045ffd44ac58f3f13eb10044836",
      "041e22a9b5514e36bd4d1dac01d5d398",
      "886d762f2a7c421382efb5502c6d42a1",
      "ab91fd625bbd43afbf8c6398193a88d0",
      "716557ad09874dcb989d75f7c74424cd",
      "77d4c0ebaae045b58efc4f789c9a2360",
      "0d622ccc56264fac8fd7508dbdbe6e29"
     ]
    },
    "id": "p5TeCUUkuGld",
    "outputId": "2f7d62a2-e78d-447a-d07b-f9e4d500fb79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'simple_agent, baseline-9b0097da' at:\n",
      "https://smith.langchain.com/o/705da240-cb86-4803-963a-cc24089b4e94/datasets/578854df-5f32-452e-a10f-42cb2291f72d/compare?selectedSessions=dc0e907c-d005-473f-a63b-c220d72b60a0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b14b20c72e648fa963643c073707ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = client.evaluate(\n",
    "    agent_chain_with_formatting,\n",
    "    data=dataset.name,\n",
    "    evaluators=[correctness_evaluator, must_mention],\n",
    "    experiment_prefix=\"simple_agent, baseline\",  # optional, experiment name prefix\n",
    "    description=\"Testing the baseline system.\",  # optional, experiment description\n",
    "    max_concurrency=4, # optional, add concurrency\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhTNe4kWrplB"
   },
   "source": [
    "## Part 2: LangGraph with Helpfulness:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1wKRddbIY_S"
   },
   "source": [
    "### Task 3: Adding Helpfulness Check and \"Loop\" Limits\n",
    "\n",
    "Now that we've done evaluation - let's see if we can add an extra step where we review the content we've generated to confirm if it fully answers the user's query!\n",
    "\n",
    "We're going to make a few key adjustments to account for this:\n",
    "\n",
    "1. We're going to add an artificial limit on how many \"loops\" the agent can go through - this will help us to avoid the potential situation where we never exit the loop.\n",
    "2. We'll add to our existing conditional edge to obtain the behaviour we desire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npTYJ8ayR5B3"
   },
   "source": [
    "First, let's define our state again - we can check the length of the state object, so we don't need additional state for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "-LQ84YhyJG0w"
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD7EV0HqSQcb"
   },
   "source": [
    "Now we can set our graph up! This process will be almost entirely the same - with the inclusion of one additional node/conditional edge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oajBwLkFVi1N"
   },
   "source": [
    "#### ğŸ—ï¸ Activity #4:\n",
    "\n",
    "Please write markdown for the following cells to explain what each is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6rN7feNVn9f"
   },
   "source": [
    "1. We are initializing a new Graph and passing in AgentState as the data structure that will be passed between agents and nodes to keep track of shared data.\n",
    "2. We are adding 2 nodes to our graph. The first one is an agent, which calls the correct model based on the current state. It will return either a response or another tool call. The second is an action node, where a tool is called, a function is executed, and results are always returned.\n",
    "\n",
    "We are still missing edges which connect the nodes, an entry point, and no conditional logic for which node to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6r6XXA5FJbVf",
    "outputId": "ff713041-e498-4f0f-a875-a03502b87729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x117dcc4d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_helpfulness_check = StateGraph(AgentState)\n",
    "\n",
    "graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
    "graph_with_helpfulness_check.add_node(\"action\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ22o2mWVrfp"
   },
   "source": [
    "This line is where we set the entry point into the graph. The initial node will always be the agent node where we run the 'call_model' function. \n",
    "\n",
    "We are still missing the edges between the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNWHwWxuRiLY",
    "outputId": "295f5a35-ceff-452a-ffb8-c52eada6a816"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x117dcc4d0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_helpfulness_check.set_entry_point(\"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsXeF6xlaXOZ"
   },
   "source": [
    "The `tool_call_or_helpful` function defines the logic that uses the state to determine the next step in the graph. This function is what connects the nodes to each other. There are 3 options it returns - `action`, `continue`, and `end`. \n",
    "If the last message contains a tool call, the function will return the string `action`. \n",
    "If the length of messages hits a certain limit (10 in this case), we terminate preemptively so that we have a cycle limit in place and don't run an inifite loop or for an extended amount of time. We return the string `END`.\n",
    "The last step is determining whether the final response is helpful or not. If it is, we end the cycle and return the string `end`. If not, we continue the cycle and return `continue` so the agent node runs again.\n",
    "\n",
    "Some issues here are that `END` and `end` are not case sensitive. If the way we evaluate the edges is case sensitite, this would cause issues.\n",
    "The final check of `if \"Y\" in helpfulness_response, end the cycle` could also cause issues. The response could say \"Yes, but ...\" which would still pass within the function.\n",
    "There also could still be an infinite loop - if the helpfulness_response doesn't pass but there are less than 10 messages the cycle will loop forever.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "z_Sq3A9SaV1O"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def tool_call_or_helpful(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  if last_message.tool_calls:\n",
    "    return \"action\"\n",
    "\n",
    "  initial_query = state[\"messages\"][0]\n",
    "  final_response = state[\"messages\"][-1]\n",
    "\n",
    "  if len(state[\"messages\"]) > 10:\n",
    "    return \"END\"\n",
    "\n",
    "  prompt_template = \"\"\"\\\n",
    "  Given an initial query and a final response, determine if the final response is extremely helpful or not. Please indicate helpfulness with a 'Y' and unhelpfulness as an 'N'.\n",
    "\n",
    "  Initial Query:\n",
    "  {initial_query}\n",
    "\n",
    "  Final Response:\n",
    "  {final_response}\"\"\"\n",
    "\n",
    "  helpfullness_prompt_template = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "  helpfulness_check_model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "  helpfulness_chain = helpfullness_prompt_template | helpfulness_check_model | StrOutputParser()\n",
    "\n",
    "  helpfulness_response = helpfulness_chain.invoke({\"initial_query\" : initial_query.content, \"final_response\" : final_response.content})\n",
    "\n",
    "  if \"Y\" in helpfulness_response:\n",
    "    return \"end\"\n",
    "  else:\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BhnBW2YVsJO"
   },
   "source": [
    "This line is adding the edges and the logic used to connect the nodes, using the function above. If the agent is called, it uses the function `tool_call_or_helpful` to determine the next step.\n",
    "If the step is to continue, call the agent node. If the step is an action, call the tool node. If the function returns \"end\", terminate the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVTKnWMbP_8T",
    "outputId": "7f729b1f-311c-4084-ceaf-0da437900c85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x117dcc4d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_helpfulness_check.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tool_call_or_helpful,\n",
    "    {\n",
    "        \"continue\" : \"agent\",\n",
    "        \"action\" : \"action\",\n",
    "        \"end\" : END\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGDLEWOIVtK0"
   },
   "source": [
    "This time adds the direct edge between the action (tool) and agent nodes. Now the graph is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbDK2MbuREgU",
    "outputId": "21a64c20-27a1-4e0e-afde-a639abaa8b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x117dcc4d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_helpfulness_check.add_edge(\"action\", \"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSI8AOaEVvT-"
   },
   "source": [
    "We are now compiling the graph. Before compilation, the graph was just the definition. Now it is ready to be run and executed.\n",
    "Compilation also might catch issues with the graph creation. For example, if you run this following line you might see an error about how the graph must have an entry point. Technically, we have added an entry point, but it might want an explicit edge from the `START` constant to a node in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "oQldl8ERQ8lf"
   },
   "outputs": [],
   "source": [
    "agent_with_helpfulness_check = graph_with_helpfulness_check.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F67FGCMRVwGz"
   },
   "source": [
    "The next line actually executes the compiled graph and outputs the different steps taken throughout the course of the graph in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3oo8E-PRK1T",
    "outputId": "f152dea8-96ad-4d29-d8b2-a064c96a8bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='Deep Research Agents are advanced AI systems designed to assist with complex research tasks. They leverage deep learning techniques and large datasets to analyze, synthesize, and generate insights across various fields of study. These agents can automate literature reviews, identify patterns in data, generate hypotheses, and even assist in writing research papers. They are used in academia, industry, and scientific research to accelerate discovery and improve the accuracy and depth of research outcomes. Would you like a more detailed explanation or specific examples of Deep Research Agents?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 158, 'total_tokens': 259, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLKK1Q9Amzc79s3zsZobmRtLJtqd7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bea6b8e7-f8ff-4d10-87c5-79c7b125a53d-0', usage_metadata={'input_tokens': 158, 'output_tokens': 101, 'total_tokens': 259, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\" : [HumanMessage(content=\"What are Deep Research Agents?\")]}\n",
    "\n",
    "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        print(values[\"messages\"])\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVmZPs6lnpsM"
   },
   "source": [
    "## Part 3: LangGraph for the \"Patterns\" of GenAI\n",
    "\n",
    "### Task 4: Helpfulness Check of Gen AI Pattern Descriptions\n",
    "\n",
    "Let's ask our system about the 3 main patterns in Generative AI:\n",
    "\n",
    "1. Context Engineering\n",
    "2. Fine-tuning\n",
    "3. Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "ZoLl7GlXoae-"
   },
   "outputs": [],
   "source": [
    "patterns = [\"Context Engineering\", \"Fine-tuning\", \"LLM-based agents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zkh0YJuCp3Zl",
    "outputId": "d847426e-71b3-47e6-b1ae-351a78d68d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Engineering is a relatively new interdisciplinary field that focuses on designing, managing, and utilizing context-aware systems and environments. It involves understanding and engineering the context in which technology operates to improve user experience, system performance, and adaptability. This can include aspects like location, time, user activity, social environment, and other situational factors that influence how systems should behave.\n",
      "\n",
      "The concept of Context Engineering gained prominence in the early 2000s with the rise of ubiquitous computing, mobile devices, and the Internet of Things (IoT). It became particularly relevant as researchers and developers sought ways to create more intelligent, responsive, and personalized systems that could adapt to the dynamic environments in which they are deployed.\n",
      "\n",
      "While the exact origin date is difficult to pinpoint, the term and its associated concepts started to break onto the scene around the mid-2000s, coinciding with advancements in context-aware computing, sensor technologies, and pervasive computing research.\n",
      "\n",
      "Would you like more detailed information on its development, key milestones, or current applications?\n",
      "\n",
      "\n",
      "\n",
      "Fine-tuning is a machine learning technique used to adapt a pre-trained model to a specific task or dataset. Instead of training a model from scratch, which can be resource-intensive and time-consuming, fine-tuning involves taking an existing model that has already learned general features from a large dataset and then further training it on a smaller, task-specific dataset. This process helps the model specialize in the new task while leveraging the knowledge it has already acquired.\n",
      "\n",
      "Fine-tuning has become a prominent approach in the development of large language models and other deep learning models, enabling rapid adaptation to various applications such as natural language processing, computer vision, and more.\n",
      "\n",
      "As for when it \"broke onto the scene,\" fine-tuning has been around for quite some time, but it gained widespread popularity and recognition with the advent of large pre-trained models like BERT (Bidirectional Encoder Representations from Transformers) in 2018. BERT's release by Google marked a significant milestone, demonstrating how pre-trained models could be effectively fine-tuned for a variety of NLP tasks, leading to a surge in research and practical applications of fine-tuning techniques.\n",
      "\n",
      "Would you like more detailed information on the history or specific developments related to fine-tuning?\n",
      "\n",
      "\n",
      "\n",
      "LLM-based agents are intelligent systems that leverage large language models (LLMs) to perform a variety of tasks, such as understanding natural language, generating human-like responses, and making decisions or taking actions based on the input they receive. These agents can be used in applications like chatbots, virtual assistants, automated customer support, and more complex decision-making systems.\n",
      "\n",
      "The concept of LLM-based agents gained significant attention and broke onto the scene around 2020-2021, coinciding with the development and release of large-scale language models like OpenAI's GPT-3 in 2020. GPT-3's impressive capabilities demonstrated the potential of large language models to serve as the core component of autonomous agents capable of performing complex language understanding and generation tasks.\n",
      "\n",
      "Since then, the field has rapidly evolved, with numerous advancements in model architectures, training techniques, and applications, making LLM-based agents a prominent area of research and industry deployment.\n",
      "\n",
      "Would you like a more detailed history or recent developments in this area?\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pattern in patterns:\n",
    "  what_is_string = f\"What is {pattern} and when did it break onto the scene??\"\n",
    "  inputs = {\"messages\" : [HumanMessage(content=what_is_string)]}\n",
    "  messages = agent_with_helpfulness_check.invoke(inputs)\n",
    "  print(messages[\"messages\"][-1].content)\n",
    "  print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
